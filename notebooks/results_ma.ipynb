{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T11:21:06.232704Z",
     "start_time": "2024-03-27T11:21:06.190999Z"
    }
   },
   "id": "9ca3ee0759bee4f1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T11:21:06.324099Z",
     "start_time": "2024-03-27T11:21:06.234459Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns  # 0.12.2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def load_json(file_name):\n",
    "    print(\"Load:\", file_name)\n",
    "    with open(file_name) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "metrics = ['step/follower/move',\n",
    "           'step/follower/take',\n",
    "           'step/follower/wait',\n",
    "           'step/speaker/silence',\n",
    "           'step/speaker/confirm',\n",
    "           'step/speaker/directive',\n",
    "           'step/speaker/move',\n",
    "           'step/speaker/decline',\n",
    "           'step/speaker/reference',\n",
    "           'step/speaker/reference/CPS',\n",
    "           'step/speaker/reference/CSP',\n",
    "           'step/speaker/reference/SCP',\n",
    "           'step/speaker/reference/SPC',\n",
    "           'step/speaker/reference/PCS',\n",
    "           'step/speaker/reference/PSC',\n",
    "           'step/speaker/take',\n",
    "           'episode/step/count',\n",
    "           'episode/outcome/success',\n",
    "           'episode/outcome/failure',\n",
    "           'episode/outcome/abort',\n",
    "           'episode/effort/follower_abs',\n",
    "           'episode/effort/follower_rel',\n",
    "           'episode/effort/speaker_abs',\n",
    "           'episode/effort/speaker_rel',\n",
    "           \"episode/effort/mean_joint_abs\",\n",
    "           \"episode/effort/mean_joint_rel\",\n",
    "           'episode/reward/time',\n",
    "           'episode/reward/goal',\n",
    "           'episode/reward/joint',\n",
    "           'episode/reward/speaker',\n",
    "           'episode/reward/follower',\n",
    "           'episode/reward/final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/additive-rnd/speaker_additive-rnd/49184/progress_test_12_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/additive-rnd/speaker_additive-rnd/49184/progress_test_21_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/additive-rnd/speaker_additive-rnd/49184/progress_test_27_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/additive-rnd/speaker_additive-rnd/92999/progress_test_12_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/additive-rnd/speaker_additive-rnd/92999/progress_test_21_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/additive-rnd/speaker_additive-rnd/92999/progress_test_27_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/additive-rnd/speaker_additive-rnd/98506/progress_test_12_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/additive-rnd/speaker_additive-rnd/98506/progress_test_21_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/additive-rnd/speaker_additive-rnd/98506/progress_test_27_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained/speaker_pretrained/49184/progress_test_12_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained/speaker_pretrained/49184/progress_test_21_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained/speaker_pretrained/49184/progress_test_27_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained/speaker_pretrained/92999/progress_test_12_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained/speaker_pretrained/92999/progress_test_21_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained/speaker_pretrained/92999/progress_test_27_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained/speaker_pretrained/98506/progress_test_12_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained/speaker_pretrained/98506/progress_test_21_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained/speaker_pretrained/98506/progress_test_27_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained_best_model/speaker_pretrained/49184/progress_test_12_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained_best_model/speaker_pretrained/49184/progress_test_21_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained_best_model/speaker_pretrained/49184/progress_test_27_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained_best_model/speaker_pretrained/92999/progress_test_12_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained_best_model/speaker_pretrained/92999/progress_test_21_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained_best_model/speaker_pretrained/92999/progress_test_27_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained_best_model/speaker_pretrained/98506/progress_test_12_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained_best_model/speaker_pretrained/98506/progress_test_21_speaker_neural.json\n",
      "Load: ../results/TakePieceEnv/follower-ma/tasks-didact-12-full/pretrained_best_model/speaker_pretrained/98506/progress_test_27_speaker_neural.json\n"
     ]
    },
    {
     "data": {
      "text/plain": "36"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "\n",
    "results_root = f\"../results/TakePieceEnv/follower-ma/tasks-didact-12-full\"\n",
    "files = glob(f\"{results_root}/**/*.json\", recursive=True)\n",
    "split_name = \"test\"\n",
    "files = [f for f in files if split_name in f]\n",
    "files = sorted(files)\n",
    "results = defaultdict(list)\n",
    "print(len(files))\n",
    "for file in files:\n",
    "    try:\n",
    "        scores = load_json(file)\n",
    "        for m in metrics:\n",
    "            try:\n",
    "                results[m].append(scores[m])\n",
    "            except:\n",
    "                results[m].append(None)\n",
    "        parts = file.split(\"/\")\n",
    "        file_name = parts[-1].split(\".\")[0]\n",
    "        file_name_parts = file_name.split(\"_\")\n",
    "        results[\"map\"].append(int(file_name_parts[2]))\n",
    "        if \"pretrained\" in file:\n",
    "            results[\"speaker\"].append(\"pretrained\")\n",
    "            if \"best_model\" in file:\n",
    "                results[\"file\"].append(\"best\")\n",
    "            else:\n",
    "                results[\"file\"].append(\"last\")\n",
    "        else:\n",
    "            results[\"speaker\"].append(\"scratch\")\n",
    "            results[\"file\"].append(\"best\")\n",
    "        results[\"seed\"].append(int(parts[-2]))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "len(results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T11:21:06.400241Z",
     "start_time": "2024-03-27T11:21:06.279782Z"
    }
   },
   "id": "7e4f9fcafebf27b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "    episode/effort/follower_abs  episode/effort/follower_rel  \\\n0                     14.106122                     1.598750   \n1                     59.661224                     1.854095   \n2                     93.918367                     1.903955   \n3                     12.522449                     1.509244   \n4                     40.530612                     1.748675   \n5                     77.775510                     1.769902   \n6                     14.346939                     1.601805   \n7                     56.065306                     1.847235   \n8                    100.767347                     1.908567   \n9                     11.240816                     1.556480   \n10                    32.820408                     1.751872   \n11                    82.506122                     1.990051   \n12                    12.995918                     1.594171   \n13                    38.571429                     1.830790   \n14                    74.065306                     1.914672   \n15                    12.285714                     1.518971   \n16                    39.077551                     1.763543   \n17                    72.187755                     1.820307   \n18                    11.012245                     1.534319   \n19                    26.636735                     1.766844   \n20                    41.991837                     1.816784   \n21                    17.457143                     1.632011   \n22                    72.844898                     1.873336   \n23                   114.359184                     1.923676   \n24                    34.930612                     1.716920   \n25                    95.800000                     1.899500   \n26                   134.779592                     1.943003   \n\n    episode/effort/mean_joint_abs  episode/effort/mean_joint_rel  \\\n0                       14.346939                       1.720263   \n1                       60.781633                       1.908197   \n2                       95.042857                       1.941054   \n3                       12.120408                       1.445571   \n4                       36.918367                       1.552942   \n5                       73.251020                       1.618654   \n6                       14.583673                       1.729118   \n7                       53.800000                       1.836580   \n8                       94.824490                       1.837823   \n9                       11.557143                       1.659454   \n10                      32.100000                       1.757428   \n11                      74.516327                       1.938977   \n12                      15.042857                       1.926616   \n13                      42.383673                       2.043194   \n14                      81.130612                       2.102586   \n15                      11.804082                       1.531068   \n16                      35.171429                       1.583603   \n17                      65.816327                       1.646918   \n18                      10.438776                       1.536435   \n19                      24.716327                       1.656420   \n20                      37.995918                       1.688131   \n21                      20.073469                       1.961278   \n22                      80.053061                       2.091322   \n23                     128.814286                       2.171380   \n24                      36.518367                       1.879245   \n25                     100.928571                       2.026373   \n26                     143.626531                       2.085339   \n\n    episode/effort/speaker_abs  episode/effort/speaker_rel  \\\n0                    14.587755                    1.841777   \n1                    61.902041                    1.962298   \n2                    96.167347                    1.978152   \n3                    11.718367                    1.381899   \n4                    33.306122                    1.357208   \n5                    68.726531                    1.467407   \n6                    14.820408                    1.856432   \n7                    51.534694                    1.825924   \n8                    88.881633                    1.767078   \n9                    11.873469                    1.762428   \n10                   31.379592                    1.762984   \n11                   66.526531                    1.887902   \n12                   17.089796                    2.259062   \n13                   46.195918                    2.255597   \n14                   88.195918                    2.290499   \n15                   11.322449                    1.543164   \n16                   31.265306                    1.403663   \n17                   59.444898                    1.473529   \n18                    9.865306                    1.538551   \n19                   22.795918                    1.545996   \n20                   34.000000                    1.559478   \n21                   22.689796                    2.290545   \n22                   87.261224                    2.309307   \n23                  143.269388                    2.419083   \n24                   38.106122                    2.041570   \n25                  106.057143                    2.153247   \n26                  152.473469                    2.227674   \n\n    episode/outcome/abort  episode/outcome/failure  episode/outcome/success  \\\n0                0.044898                 0.000000                 0.955102   \n1                0.334694                 0.012245                 0.653061   \n2                0.440816                 0.004082                 0.555102   \n3                0.048980                 0.000000                 0.951020   \n4                0.171429                 0.000000                 0.828571   \n5                0.371429                 0.004082                 0.624490   \n6                0.044898                 0.012245                 0.942857   \n7                0.281633                 0.016327                 0.702041   \n8                0.506122                 0.016327                 0.477551   \n9                0.020408                 0.000000                 0.979592   \n10               0.073469                 0.032653                 0.893878   \n11               0.277551                 0.040816                 0.681633   \n12               0.032653                 0.000000                 0.967347   \n13               0.093878                 0.012245                 0.893878   \n14               0.257143                 0.012245                 0.730612   \n15               0.032653                 0.024490                 0.942857   \n16               0.114286                 0.061224                 0.824490   \n17               0.281633                 0.048980                 0.669388   \n18               0.020408                 0.008163                 0.971429   \n19               0.016327                 0.000000                 0.983673   \n20               0.053061                 0.024490                 0.922449   \n21               0.110204                 0.000000                 0.889796   \n22               0.502041                 0.000000                 0.497959   \n23               0.640816                 0.000000                 0.359184   \n24               0.477551                 0.004082                 0.518367   \n25               0.718367                 0.004082                 0.277551   \n26               0.783673                 0.020408                 0.195918   \n\n    episode/reward/final  ...  step/speaker/move  step/speaker/reference  \\\n0               1.574939  ...           0.625239                0.140812   \n1               0.619138  ...           0.494199                0.279405   \n2               0.306231  ...           0.510513                0.281407   \n3               1.600969  ...           0.542279                0.044707   \n4               1.208276  ...           0.365025                0.091751   \n5               0.591394  ...           0.348712                0.128203   \n6               1.548347  ...           0.603108                0.164017   \n7               0.786643  ...           0.420541                0.246703   \n8               0.131786  ...           0.337462                0.286512   \n9               1.684133  ...           0.349810                0.130359   \n10              1.419811  ...           0.462068                0.141634   \n11              0.743953  ...           0.386247                0.163233   \n12              1.596765  ...           0.413833                0.203973   \n13              1.327551  ...           0.596621                0.239146   \n14              0.801161  ...           0.609295                0.279759   \n15              1.598571  ...           0.306810                0.081212   \n16              1.231561  ...           0.458760                0.063996   \n17              0.759849  ...           0.515156                0.051335   \n18              1.686480  ...           0.299278                0.084760   \n19              1.670699  ...           0.434363                0.110586   \n20              1.515212  ...           0.456749                0.121344   \n21              1.332592  ...           0.437875                0.255868   \n22              0.114959  ...           0.609274                0.300401   \n23             -0.333473  ...           0.537104                0.408813   \n24              0.214347  ...           0.753060                0.038729   \n25             -0.568689  ...           0.757146                0.153735   \n26             -0.792460  ...           0.668922                0.230119   \n\n    step/speaker/reference/CPS  step/speaker/reference/CSP  \\\n0                     0.007121                         NaN   \n1                     0.009727                    0.000068   \n2                     0.006169                         NaN   \n3                     0.004718                         NaN   \n4                     0.009535                    0.003256   \n5                     0.022107                    0.004621   \n6                     0.020393                    0.000255   \n7                     0.080387                    0.007527   \n8                     0.127438                    0.007279   \n9                     0.002721                    0.029278   \n10                    0.007646                    0.011813   \n11                    0.002395                    0.010526   \n12                    0.010314                         NaN   \n13                    0.018026                    0.000413   \n14                    0.037479                    0.001093   \n15                    0.004088                    0.001134   \n16                    0.004077                         NaN   \n17                    0.001503                    0.000227   \n18                    0.009516                    0.000510   \n19                    0.013892                    0.001850   \n20                    0.016223                    0.005430   \n21                    0.062424                    0.033933   \n22                    0.046412                    0.048957   \n23                    0.054957                    0.063268   \n24                    0.022336                    0.000272   \n25                    0.061358                    0.000814   \n26                    0.049364                    0.001614   \n\n    step/speaker/reference/PCS  step/speaker/reference/PSC  \\\n0                     0.025684                    0.000975   \n1                     0.029701                    0.003410   \n2                     0.031465                    0.007376   \n3                     0.016227                    0.011924   \n4                     0.021217                    0.026971   \n5                     0.018469                    0.039374   \n6                     0.105587                    0.003356   \n7                     0.073986                    0.005872   \n8                     0.049100                    0.004214   \n9                     0.077906                    0.000136   \n10                    0.063603                    0.000451   \n11                    0.073906                    0.000794   \n12                         NaN                    0.092123   \n13                         NaN                    0.114537   \n14                         NaN                    0.130262   \n15                    0.007039                    0.068951   \n16                    0.012874                    0.047044   \n17                    0.019150                    0.030456   \n18                    0.020756                    0.010236   \n19                    0.015499                    0.020230   \n20                    0.012529                    0.027326   \n21                         NaN                    0.079170   \n22                         NaN                    0.113257   \n23                         NaN                    0.118941   \n24                         NaN                    0.015713   \n25                    0.002967                    0.087887   \n26                    0.003671                    0.175061   \n\n   step/speaker/reference/SCP  step/speaker/reference/SPC  \\\n0                    0.069208                    0.037824   \n1                    0.077939                    0.158560   \n2                    0.060398                    0.175998   \n3                    0.004008                    0.007830   \n4                    0.009768                    0.021003   \n5                    0.008317                    0.035315   \n6                    0.006874                    0.027553   \n7                    0.042131                    0.036800   \n8                    0.076024                    0.022458   \n9                    0.020317                         NaN   \n10                   0.058121                         NaN   \n11                   0.075613                         NaN   \n12                   0.101536                         NaN   \n13                   0.104422                    0.001748   \n14                   0.108540                    0.002386   \n15                        NaN                         NaN   \n16                        NaN                         NaN   \n17                        NaN                         NaN   \n18                   0.042342                    0.001399   \n19                   0.058100                    0.001016   \n20                   0.058881                    0.000954   \n21                   0.080205                    0.000136   \n22                   0.090550                    0.001224   \n23                   0.144504                    0.027143   \n24                        NaN                    0.000408   \n25                        NaN                    0.000710   \n26                   0.000051                    0.000357   \n\n    step/speaker/silence step/speaker/take  \n0               0.082796          0.007249  \n1               0.120266          0.015601  \n2               0.120194          0.016865  \n3               0.149148          0.091762  \n4               0.218912          0.092383  \n5               0.181264          0.067591  \n6               0.053332          0.000499  \n7               0.083817          0.005977  \n8               0.141924          0.012275  \n9               0.123588          0.256047  \n10              0.155481          0.151392  \n11              0.088392          0.268719  \n12                   NaN          0.382194  \n13                   NaN          0.163706  \n14                   NaN          0.110649  \n15              0.205018          0.339512  \n16              0.282629          0.143573  \n17              0.251589          0.121451  \n18              0.194490          0.287502  \n19              0.245517          0.157633  \n20              0.250319          0.105243  \n21                   NaN          0.295093  \n22                   NaN          0.087659  \n23                   NaN          0.052737  \n24                   NaN          0.208211  \n25                   NaN          0.089119  \n26                   NaN          0.100959  \n\n[27 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>episode/effort/follower_abs</th>\n      <th>episode/effort/follower_rel</th>\n      <th>episode/effort/mean_joint_abs</th>\n      <th>episode/effort/mean_joint_rel</th>\n      <th>episode/effort/speaker_abs</th>\n      <th>episode/effort/speaker_rel</th>\n      <th>episode/outcome/abort</th>\n      <th>episode/outcome/failure</th>\n      <th>episode/outcome/success</th>\n      <th>episode/reward/final</th>\n      <th>...</th>\n      <th>step/speaker/move</th>\n      <th>step/speaker/reference</th>\n      <th>step/speaker/reference/CPS</th>\n      <th>step/speaker/reference/CSP</th>\n      <th>step/speaker/reference/PCS</th>\n      <th>step/speaker/reference/PSC</th>\n      <th>step/speaker/reference/SCP</th>\n      <th>step/speaker/reference/SPC</th>\n      <th>step/speaker/silence</th>\n      <th>step/speaker/take</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14.106122</td>\n      <td>1.598750</td>\n      <td>14.346939</td>\n      <td>1.720263</td>\n      <td>14.587755</td>\n      <td>1.841777</td>\n      <td>0.044898</td>\n      <td>0.000000</td>\n      <td>0.955102</td>\n      <td>1.574939</td>\n      <td>...</td>\n      <td>0.625239</td>\n      <td>0.140812</td>\n      <td>0.007121</td>\n      <td>NaN</td>\n      <td>0.025684</td>\n      <td>0.000975</td>\n      <td>0.069208</td>\n      <td>0.037824</td>\n      <td>0.082796</td>\n      <td>0.007249</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>59.661224</td>\n      <td>1.854095</td>\n      <td>60.781633</td>\n      <td>1.908197</td>\n      <td>61.902041</td>\n      <td>1.962298</td>\n      <td>0.334694</td>\n      <td>0.012245</td>\n      <td>0.653061</td>\n      <td>0.619138</td>\n      <td>...</td>\n      <td>0.494199</td>\n      <td>0.279405</td>\n      <td>0.009727</td>\n      <td>0.000068</td>\n      <td>0.029701</td>\n      <td>0.003410</td>\n      <td>0.077939</td>\n      <td>0.158560</td>\n      <td>0.120266</td>\n      <td>0.015601</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>93.918367</td>\n      <td>1.903955</td>\n      <td>95.042857</td>\n      <td>1.941054</td>\n      <td>96.167347</td>\n      <td>1.978152</td>\n      <td>0.440816</td>\n      <td>0.004082</td>\n      <td>0.555102</td>\n      <td>0.306231</td>\n      <td>...</td>\n      <td>0.510513</td>\n      <td>0.281407</td>\n      <td>0.006169</td>\n      <td>NaN</td>\n      <td>0.031465</td>\n      <td>0.007376</td>\n      <td>0.060398</td>\n      <td>0.175998</td>\n      <td>0.120194</td>\n      <td>0.016865</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12.522449</td>\n      <td>1.509244</td>\n      <td>12.120408</td>\n      <td>1.445571</td>\n      <td>11.718367</td>\n      <td>1.381899</td>\n      <td>0.048980</td>\n      <td>0.000000</td>\n      <td>0.951020</td>\n      <td>1.600969</td>\n      <td>...</td>\n      <td>0.542279</td>\n      <td>0.044707</td>\n      <td>0.004718</td>\n      <td>NaN</td>\n      <td>0.016227</td>\n      <td>0.011924</td>\n      <td>0.004008</td>\n      <td>0.007830</td>\n      <td>0.149148</td>\n      <td>0.091762</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40.530612</td>\n      <td>1.748675</td>\n      <td>36.918367</td>\n      <td>1.552942</td>\n      <td>33.306122</td>\n      <td>1.357208</td>\n      <td>0.171429</td>\n      <td>0.000000</td>\n      <td>0.828571</td>\n      <td>1.208276</td>\n      <td>...</td>\n      <td>0.365025</td>\n      <td>0.091751</td>\n      <td>0.009535</td>\n      <td>0.003256</td>\n      <td>0.021217</td>\n      <td>0.026971</td>\n      <td>0.009768</td>\n      <td>0.021003</td>\n      <td>0.218912</td>\n      <td>0.092383</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>77.775510</td>\n      <td>1.769902</td>\n      <td>73.251020</td>\n      <td>1.618654</td>\n      <td>68.726531</td>\n      <td>1.467407</td>\n      <td>0.371429</td>\n      <td>0.004082</td>\n      <td>0.624490</td>\n      <td>0.591394</td>\n      <td>...</td>\n      <td>0.348712</td>\n      <td>0.128203</td>\n      <td>0.022107</td>\n      <td>0.004621</td>\n      <td>0.018469</td>\n      <td>0.039374</td>\n      <td>0.008317</td>\n      <td>0.035315</td>\n      <td>0.181264</td>\n      <td>0.067591</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14.346939</td>\n      <td>1.601805</td>\n      <td>14.583673</td>\n      <td>1.729118</td>\n      <td>14.820408</td>\n      <td>1.856432</td>\n      <td>0.044898</td>\n      <td>0.012245</td>\n      <td>0.942857</td>\n      <td>1.548347</td>\n      <td>...</td>\n      <td>0.603108</td>\n      <td>0.164017</td>\n      <td>0.020393</td>\n      <td>0.000255</td>\n      <td>0.105587</td>\n      <td>0.003356</td>\n      <td>0.006874</td>\n      <td>0.027553</td>\n      <td>0.053332</td>\n      <td>0.000499</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>56.065306</td>\n      <td>1.847235</td>\n      <td>53.800000</td>\n      <td>1.836580</td>\n      <td>51.534694</td>\n      <td>1.825924</td>\n      <td>0.281633</td>\n      <td>0.016327</td>\n      <td>0.702041</td>\n      <td>0.786643</td>\n      <td>...</td>\n      <td>0.420541</td>\n      <td>0.246703</td>\n      <td>0.080387</td>\n      <td>0.007527</td>\n      <td>0.073986</td>\n      <td>0.005872</td>\n      <td>0.042131</td>\n      <td>0.036800</td>\n      <td>0.083817</td>\n      <td>0.005977</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>100.767347</td>\n      <td>1.908567</td>\n      <td>94.824490</td>\n      <td>1.837823</td>\n      <td>88.881633</td>\n      <td>1.767078</td>\n      <td>0.506122</td>\n      <td>0.016327</td>\n      <td>0.477551</td>\n      <td>0.131786</td>\n      <td>...</td>\n      <td>0.337462</td>\n      <td>0.286512</td>\n      <td>0.127438</td>\n      <td>0.007279</td>\n      <td>0.049100</td>\n      <td>0.004214</td>\n      <td>0.076024</td>\n      <td>0.022458</td>\n      <td>0.141924</td>\n      <td>0.012275</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>11.240816</td>\n      <td>1.556480</td>\n      <td>11.557143</td>\n      <td>1.659454</td>\n      <td>11.873469</td>\n      <td>1.762428</td>\n      <td>0.020408</td>\n      <td>0.000000</td>\n      <td>0.979592</td>\n      <td>1.684133</td>\n      <td>...</td>\n      <td>0.349810</td>\n      <td>0.130359</td>\n      <td>0.002721</td>\n      <td>0.029278</td>\n      <td>0.077906</td>\n      <td>0.000136</td>\n      <td>0.020317</td>\n      <td>NaN</td>\n      <td>0.123588</td>\n      <td>0.256047</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>32.820408</td>\n      <td>1.751872</td>\n      <td>32.100000</td>\n      <td>1.757428</td>\n      <td>31.379592</td>\n      <td>1.762984</td>\n      <td>0.073469</td>\n      <td>0.032653</td>\n      <td>0.893878</td>\n      <td>1.419811</td>\n      <td>...</td>\n      <td>0.462068</td>\n      <td>0.141634</td>\n      <td>0.007646</td>\n      <td>0.011813</td>\n      <td>0.063603</td>\n      <td>0.000451</td>\n      <td>0.058121</td>\n      <td>NaN</td>\n      <td>0.155481</td>\n      <td>0.151392</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>82.506122</td>\n      <td>1.990051</td>\n      <td>74.516327</td>\n      <td>1.938977</td>\n      <td>66.526531</td>\n      <td>1.887902</td>\n      <td>0.277551</td>\n      <td>0.040816</td>\n      <td>0.681633</td>\n      <td>0.743953</td>\n      <td>...</td>\n      <td>0.386247</td>\n      <td>0.163233</td>\n      <td>0.002395</td>\n      <td>0.010526</td>\n      <td>0.073906</td>\n      <td>0.000794</td>\n      <td>0.075613</td>\n      <td>NaN</td>\n      <td>0.088392</td>\n      <td>0.268719</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12.995918</td>\n      <td>1.594171</td>\n      <td>15.042857</td>\n      <td>1.926616</td>\n      <td>17.089796</td>\n      <td>2.259062</td>\n      <td>0.032653</td>\n      <td>0.000000</td>\n      <td>0.967347</td>\n      <td>1.596765</td>\n      <td>...</td>\n      <td>0.413833</td>\n      <td>0.203973</td>\n      <td>0.010314</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.092123</td>\n      <td>0.101536</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.382194</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>38.571429</td>\n      <td>1.830790</td>\n      <td>42.383673</td>\n      <td>2.043194</td>\n      <td>46.195918</td>\n      <td>2.255597</td>\n      <td>0.093878</td>\n      <td>0.012245</td>\n      <td>0.893878</td>\n      <td>1.327551</td>\n      <td>...</td>\n      <td>0.596621</td>\n      <td>0.239146</td>\n      <td>0.018026</td>\n      <td>0.000413</td>\n      <td>NaN</td>\n      <td>0.114537</td>\n      <td>0.104422</td>\n      <td>0.001748</td>\n      <td>NaN</td>\n      <td>0.163706</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>74.065306</td>\n      <td>1.914672</td>\n      <td>81.130612</td>\n      <td>2.102586</td>\n      <td>88.195918</td>\n      <td>2.290499</td>\n      <td>0.257143</td>\n      <td>0.012245</td>\n      <td>0.730612</td>\n      <td>0.801161</td>\n      <td>...</td>\n      <td>0.609295</td>\n      <td>0.279759</td>\n      <td>0.037479</td>\n      <td>0.001093</td>\n      <td>NaN</td>\n      <td>0.130262</td>\n      <td>0.108540</td>\n      <td>0.002386</td>\n      <td>NaN</td>\n      <td>0.110649</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>12.285714</td>\n      <td>1.518971</td>\n      <td>11.804082</td>\n      <td>1.531068</td>\n      <td>11.322449</td>\n      <td>1.543164</td>\n      <td>0.032653</td>\n      <td>0.024490</td>\n      <td>0.942857</td>\n      <td>1.598571</td>\n      <td>...</td>\n      <td>0.306810</td>\n      <td>0.081212</td>\n      <td>0.004088</td>\n      <td>0.001134</td>\n      <td>0.007039</td>\n      <td>0.068951</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.205018</td>\n      <td>0.339512</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>39.077551</td>\n      <td>1.763543</td>\n      <td>35.171429</td>\n      <td>1.583603</td>\n      <td>31.265306</td>\n      <td>1.403663</td>\n      <td>0.114286</td>\n      <td>0.061224</td>\n      <td>0.824490</td>\n      <td>1.231561</td>\n      <td>...</td>\n      <td>0.458760</td>\n      <td>0.063996</td>\n      <td>0.004077</td>\n      <td>NaN</td>\n      <td>0.012874</td>\n      <td>0.047044</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.282629</td>\n      <td>0.143573</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>72.187755</td>\n      <td>1.820307</td>\n      <td>65.816327</td>\n      <td>1.646918</td>\n      <td>59.444898</td>\n      <td>1.473529</td>\n      <td>0.281633</td>\n      <td>0.048980</td>\n      <td>0.669388</td>\n      <td>0.759849</td>\n      <td>...</td>\n      <td>0.515156</td>\n      <td>0.051335</td>\n      <td>0.001503</td>\n      <td>0.000227</td>\n      <td>0.019150</td>\n      <td>0.030456</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.251589</td>\n      <td>0.121451</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>11.012245</td>\n      <td>1.534319</td>\n      <td>10.438776</td>\n      <td>1.536435</td>\n      <td>9.865306</td>\n      <td>1.538551</td>\n      <td>0.020408</td>\n      <td>0.008163</td>\n      <td>0.971429</td>\n      <td>1.686480</td>\n      <td>...</td>\n      <td>0.299278</td>\n      <td>0.084760</td>\n      <td>0.009516</td>\n      <td>0.000510</td>\n      <td>0.020756</td>\n      <td>0.010236</td>\n      <td>0.042342</td>\n      <td>0.001399</td>\n      <td>0.194490</td>\n      <td>0.287502</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>26.636735</td>\n      <td>1.766844</td>\n      <td>24.716327</td>\n      <td>1.656420</td>\n      <td>22.795918</td>\n      <td>1.545996</td>\n      <td>0.016327</td>\n      <td>0.000000</td>\n      <td>0.983673</td>\n      <td>1.670699</td>\n      <td>...</td>\n      <td>0.434363</td>\n      <td>0.110586</td>\n      <td>0.013892</td>\n      <td>0.001850</td>\n      <td>0.015499</td>\n      <td>0.020230</td>\n      <td>0.058100</td>\n      <td>0.001016</td>\n      <td>0.245517</td>\n      <td>0.157633</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>41.991837</td>\n      <td>1.816784</td>\n      <td>37.995918</td>\n      <td>1.688131</td>\n      <td>34.000000</td>\n      <td>1.559478</td>\n      <td>0.053061</td>\n      <td>0.024490</td>\n      <td>0.922449</td>\n      <td>1.515212</td>\n      <td>...</td>\n      <td>0.456749</td>\n      <td>0.121344</td>\n      <td>0.016223</td>\n      <td>0.005430</td>\n      <td>0.012529</td>\n      <td>0.027326</td>\n      <td>0.058881</td>\n      <td>0.000954</td>\n      <td>0.250319</td>\n      <td>0.105243</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>17.457143</td>\n      <td>1.632011</td>\n      <td>20.073469</td>\n      <td>1.961278</td>\n      <td>22.689796</td>\n      <td>2.290545</td>\n      <td>0.110204</td>\n      <td>0.000000</td>\n      <td>0.889796</td>\n      <td>1.332592</td>\n      <td>...</td>\n      <td>0.437875</td>\n      <td>0.255868</td>\n      <td>0.062424</td>\n      <td>0.033933</td>\n      <td>NaN</td>\n      <td>0.079170</td>\n      <td>0.080205</td>\n      <td>0.000136</td>\n      <td>NaN</td>\n      <td>0.295093</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>72.844898</td>\n      <td>1.873336</td>\n      <td>80.053061</td>\n      <td>2.091322</td>\n      <td>87.261224</td>\n      <td>2.309307</td>\n      <td>0.502041</td>\n      <td>0.000000</td>\n      <td>0.497959</td>\n      <td>0.114959</td>\n      <td>...</td>\n      <td>0.609274</td>\n      <td>0.300401</td>\n      <td>0.046412</td>\n      <td>0.048957</td>\n      <td>NaN</td>\n      <td>0.113257</td>\n      <td>0.090550</td>\n      <td>0.001224</td>\n      <td>NaN</td>\n      <td>0.087659</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>114.359184</td>\n      <td>1.923676</td>\n      <td>128.814286</td>\n      <td>2.171380</td>\n      <td>143.269388</td>\n      <td>2.419083</td>\n      <td>0.640816</td>\n      <td>0.000000</td>\n      <td>0.359184</td>\n      <td>-0.333473</td>\n      <td>...</td>\n      <td>0.537104</td>\n      <td>0.408813</td>\n      <td>0.054957</td>\n      <td>0.063268</td>\n      <td>NaN</td>\n      <td>0.118941</td>\n      <td>0.144504</td>\n      <td>0.027143</td>\n      <td>NaN</td>\n      <td>0.052737</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>34.930612</td>\n      <td>1.716920</td>\n      <td>36.518367</td>\n      <td>1.879245</td>\n      <td>38.106122</td>\n      <td>2.041570</td>\n      <td>0.477551</td>\n      <td>0.004082</td>\n      <td>0.518367</td>\n      <td>0.214347</td>\n      <td>...</td>\n      <td>0.753060</td>\n      <td>0.038729</td>\n      <td>0.022336</td>\n      <td>0.000272</td>\n      <td>NaN</td>\n      <td>0.015713</td>\n      <td>NaN</td>\n      <td>0.000408</td>\n      <td>NaN</td>\n      <td>0.208211</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>95.800000</td>\n      <td>1.899500</td>\n      <td>100.928571</td>\n      <td>2.026373</td>\n      <td>106.057143</td>\n      <td>2.153247</td>\n      <td>0.718367</td>\n      <td>0.004082</td>\n      <td>0.277551</td>\n      <td>-0.568689</td>\n      <td>...</td>\n      <td>0.757146</td>\n      <td>0.153735</td>\n      <td>0.061358</td>\n      <td>0.000814</td>\n      <td>0.002967</td>\n      <td>0.087887</td>\n      <td>NaN</td>\n      <td>0.000710</td>\n      <td>NaN</td>\n      <td>0.089119</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>134.779592</td>\n      <td>1.943003</td>\n      <td>143.626531</td>\n      <td>2.085339</td>\n      <td>152.473469</td>\n      <td>2.227674</td>\n      <td>0.783673</td>\n      <td>0.020408</td>\n      <td>0.195918</td>\n      <td>-0.792460</td>\n      <td>...</td>\n      <td>0.668922</td>\n      <td>0.230119</td>\n      <td>0.049364</td>\n      <td>0.001614</td>\n      <td>0.003671</td>\n      <td>0.175061</td>\n      <td>0.000051</td>\n      <td>0.000357</td>\n      <td>NaN</td>\n      <td>0.100959</td>\n    </tr>\n  </tbody>\n</table>\n<p>27 rows Ã— 36 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(results)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T11:21:06.566049Z",
     "start_time": "2024-03-27T11:21:06.341012Z"
    }
   },
   "id": "19b14f63fee6988b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "map                12    21    27     12     21     27    12    21    27  \\\nfile speaker                                                               \nbest pretrained  0.79  0.59  0.49  11.65  33.72  49.54  1.08  0.41  0.13   \n     scratch     0.95  0.73  0.55   8.04  27.61  47.69  1.57  0.87  0.34   \nlast pretrained  0.96  0.87  0.69   7.20  19.35  37.27  1.63  1.33  0.77   \n\nmap                12    21    27  \nfile speaker                       \nbest pretrained  1.79  1.92  1.98  \n     scratch     1.63  1.77  1.80  \nlast pretrained  1.71  1.79  1.90  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>map</th>\n      <th>12</th>\n      <th>21</th>\n      <th>27</th>\n      <th>12</th>\n      <th>21</th>\n      <th>27</th>\n      <th>12</th>\n      <th>21</th>\n      <th>27</th>\n      <th>12</th>\n      <th>21</th>\n      <th>27</th>\n    </tr>\n    <tr>\n      <th>file</th>\n      <th>speaker</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">best</th>\n      <th>pretrained</th>\n      <td>0.79</td>\n      <td>0.59</td>\n      <td>0.49</td>\n      <td>11.65</td>\n      <td>33.72</td>\n      <td>49.54</td>\n      <td>1.08</td>\n      <td>0.41</td>\n      <td>0.13</td>\n      <td>1.79</td>\n      <td>1.92</td>\n      <td>1.98</td>\n    </tr>\n    <tr>\n      <th>scratch</th>\n      <td>0.95</td>\n      <td>0.73</td>\n      <td>0.55</td>\n      <td>8.04</td>\n      <td>27.61</td>\n      <td>47.69</td>\n      <td>1.57</td>\n      <td>0.87</td>\n      <td>0.34</td>\n      <td>1.63</td>\n      <td>1.77</td>\n      <td>1.80</td>\n    </tr>\n    <tr>\n      <th>last</th>\n      <th>pretrained</th>\n      <td>0.96</td>\n      <td>0.87</td>\n      <td>0.69</td>\n      <td>7.20</td>\n      <td>19.35</td>\n      <td>37.27</td>\n      <td>1.63</td>\n      <td>1.33</td>\n      <td>0.77</td>\n      <td>1.71</td>\n      <td>1.79</td>\n      <td>1.90</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Success and Reward per Map over all Speakers (avg)\n",
    "relevant_values = [\"episode/outcome/success\", \"episode/step/count\", \"episode/reward/final\", \"episode/effort/mean_joint_rel\"]\n",
    "dff = [df.pivot_table(value, [\"file\",\"speaker\"], \"map\").round(2) for value in relevant_values]\n",
    "pd.concat(dff, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T11:21:06.567324Z",
     "start_time": "2024-03-27T11:21:06.420454Z"
    }
   },
   "id": "619811fdbafdc652"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "map                      12    21    27     12     21     27    12    21  \\\nfile speaker    seed                                                       \nbest pretrained 49184  0.97  0.98  0.92   6.65  14.84  22.79  1.69  1.67   \n                92999  0.89  0.50  0.36   9.73  37.41  58.18  1.33  0.11   \n                98506  0.52  0.28  0.20  18.58  48.91  67.64  0.21 -0.57   \n     scratch    49184  0.96  0.65  0.56   8.00  30.82  47.89  1.57  0.62   \n                92999  0.95  0.83  0.62   7.95  22.93  43.65  1.60  1.21   \n                98506  0.94  0.70  0.48   8.18  29.07  51.54  1.55  0.79   \nlast pretrained 49184  0.98  0.89  0.68   6.78  16.96  35.58  1.68  1.42   \n                92999  0.97  0.89  0.73   7.49  20.07  37.67  1.60  1.33   \n                98506  0.94  0.82  0.67   7.34  21.03  38.56  1.60  1.23   \n\nmap                      27    12    21    27  \nfile speaker    seed                           \nbest pretrained 49184  1.52  1.54  1.66  1.69  \n                92999 -0.33  1.96  2.09  2.17  \n                98506 -0.79  1.88  2.03  2.09  \n     scratch    49184  0.31  1.72  1.91  1.94  \n                92999  0.59  1.45  1.55  1.62  \n                98506  0.13  1.73  1.84  1.84  \nlast pretrained 49184  0.74  1.66  1.76  1.94  \n                92999  0.80  1.93  2.04  2.10  \n                98506  0.76  1.53  1.58  1.65  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>map</th>\n      <th>12</th>\n      <th>21</th>\n      <th>27</th>\n      <th>12</th>\n      <th>21</th>\n      <th>27</th>\n      <th>12</th>\n      <th>21</th>\n      <th>27</th>\n      <th>12</th>\n      <th>21</th>\n      <th>27</th>\n    </tr>\n    <tr>\n      <th>file</th>\n      <th>speaker</th>\n      <th>seed</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"6\" valign=\"top\">best</th>\n      <th rowspan=\"3\" valign=\"top\">pretrained</th>\n      <th>49184</th>\n      <td>0.97</td>\n      <td>0.98</td>\n      <td>0.92</td>\n      <td>6.65</td>\n      <td>14.84</td>\n      <td>22.79</td>\n      <td>1.69</td>\n      <td>1.67</td>\n      <td>1.52</td>\n      <td>1.54</td>\n      <td>1.66</td>\n      <td>1.69</td>\n    </tr>\n    <tr>\n      <th>92999</th>\n      <td>0.89</td>\n      <td>0.50</td>\n      <td>0.36</td>\n      <td>9.73</td>\n      <td>37.41</td>\n      <td>58.18</td>\n      <td>1.33</td>\n      <td>0.11</td>\n      <td>-0.33</td>\n      <td>1.96</td>\n      <td>2.09</td>\n      <td>2.17</td>\n    </tr>\n    <tr>\n      <th>98506</th>\n      <td>0.52</td>\n      <td>0.28</td>\n      <td>0.20</td>\n      <td>18.58</td>\n      <td>48.91</td>\n      <td>67.64</td>\n      <td>0.21</td>\n      <td>-0.57</td>\n      <td>-0.79</td>\n      <td>1.88</td>\n      <td>2.03</td>\n      <td>2.09</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">scratch</th>\n      <th>49184</th>\n      <td>0.96</td>\n      <td>0.65</td>\n      <td>0.56</td>\n      <td>8.00</td>\n      <td>30.82</td>\n      <td>47.89</td>\n      <td>1.57</td>\n      <td>0.62</td>\n      <td>0.31</td>\n      <td>1.72</td>\n      <td>1.91</td>\n      <td>1.94</td>\n    </tr>\n    <tr>\n      <th>92999</th>\n      <td>0.95</td>\n      <td>0.83</td>\n      <td>0.62</td>\n      <td>7.95</td>\n      <td>22.93</td>\n      <td>43.65</td>\n      <td>1.60</td>\n      <td>1.21</td>\n      <td>0.59</td>\n      <td>1.45</td>\n      <td>1.55</td>\n      <td>1.62</td>\n    </tr>\n    <tr>\n      <th>98506</th>\n      <td>0.94</td>\n      <td>0.70</td>\n      <td>0.48</td>\n      <td>8.18</td>\n      <td>29.07</td>\n      <td>51.54</td>\n      <td>1.55</td>\n      <td>0.79</td>\n      <td>0.13</td>\n      <td>1.73</td>\n      <td>1.84</td>\n      <td>1.84</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">last</th>\n      <th rowspan=\"3\" valign=\"top\">pretrained</th>\n      <th>49184</th>\n      <td>0.98</td>\n      <td>0.89</td>\n      <td>0.68</td>\n      <td>6.78</td>\n      <td>16.96</td>\n      <td>35.58</td>\n      <td>1.68</td>\n      <td>1.42</td>\n      <td>0.74</td>\n      <td>1.66</td>\n      <td>1.76</td>\n      <td>1.94</td>\n    </tr>\n    <tr>\n      <th>92999</th>\n      <td>0.97</td>\n      <td>0.89</td>\n      <td>0.73</td>\n      <td>7.49</td>\n      <td>20.07</td>\n      <td>37.67</td>\n      <td>1.60</td>\n      <td>1.33</td>\n      <td>0.80</td>\n      <td>1.93</td>\n      <td>2.04</td>\n      <td>2.10</td>\n    </tr>\n    <tr>\n      <th>98506</th>\n      <td>0.94</td>\n      <td>0.82</td>\n      <td>0.67</td>\n      <td>7.34</td>\n      <td>21.03</td>\n      <td>38.56</td>\n      <td>1.60</td>\n      <td>1.23</td>\n      <td>0.76</td>\n      <td>1.53</td>\n      <td>1.58</td>\n      <td>1.65</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Success and Reward per Map over all Speakers (avg)\n",
    "relevant_values = [\"episode/outcome/success\", \"episode/step/count\", \"episode/reward/final\", \"episode/effort/mean_joint_rel\"]\n",
    "dff = [df.pivot_table(value, [\"file\", \"speaker\", \"seed\"], \"map\").round(2) for value in relevant_values]\n",
    "pd.concat(dff, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T11:21:06.758897Z",
     "start_time": "2024-03-27T11:21:06.506921Z"
    }
   },
   "id": "4d044321b103776a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
